import numpy as np
import matplotlib.pyplot as plt

#step1
def initialize_parameters(lenw):
      w = np.random.randn(1,lenw)
      # w = np.zeros((1,lenw))
      b = 0
      return w,b

#step2
def forward_prop(X,w,b):
    z = np.dot(w,X)+ b
    return z

#step3
def cost_function(x,y):
    m = y.shape[1]
    J = (1/(2*m))*np.sum(np.sqaure(z-y))
    return J

#step4
def back_prop(X,y,z):
    m = y.shape[1]
    dz = (1/m)*(z-y)
    dw = np.dot(dz,X.T)
    db = np.sum(dz)
    return dw,db     

#step5
def gradient_descent_update(w,b,dw,db,learning_rate):
    w = w - learning_rate*dw
    b = b - learning_rate*db
    return w,b

#step6
def linear_regression_model(X_train,y_train,X_val,y_val,learning_rate,epochs):
    
    lenw = X_train.shape[0]
    w,b = initialize_parameters(lenw)
    
    for i in range(1,epochs+1):
        z_train = forward_prop(X_train,w,b)
        cost_train = cost_function(z_train,y_train)
        dw,db = back_prop(X_train,y_train,z_train)
        w,b = gradient_descent_update(w,b,dw,db,learning_rate)
        
        if i%10==0:
            costs_train.append(cost_train)
            
            MAE_train = (1/m_train)*np.sum(np.abs(z_train-y_train))
            
            z_val = forward_prop(X_val,w,b)
            cost_val = cost_function(z_val,y_val)
            MAE_val = (1/m_val)*np.sum(np.abs(z_val-y_val))
            
            print('Epochs '+str(i)+'/'+str(epochs)+':')
            print('Training cost '+str(cost_train)+'|'+'Validation cost '+str(cost_val))
            print('Training MAE '+str(MAE_train)+'|'+'Validation_MAE '+str(MAE_val))
            
            plt.plot(costs_train)
            plt.xlabel('Iterations(per tens)')
            plt.ylabel('Training cost')
            plt.title('Learning rate '+str(learning_rate))
            plt.show()
